{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c3f3fd3-e07e-4b0a-9bf6-3bf8579c961d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02d87c11-7891-4335-95e7-0938ce5de333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# LAB - Feature Engineering with Feature Store\n",
    "\n",
    "Welcome to the \"Feature Engineering with Feature Store\" In this lesson, you will learn how to load and prepare a dataset for feature selection, explore and manipulate a feature table through Databricks UI, perform feature selection on specific columns, create a new feature table, access feature table details using both UI and API, merge two feature tables based on a common identifier, and efficiently delete unnecessary feature tables. Get ready to enhance your feature engineering skillsâ€”let's dive in!\n",
    "\n",
    "**Lab Outline:**\n",
    "\n",
    "In this Lab, you will learn how to:\n",
    "\n",
    "1. Load and Prepare Dataset for Feature Selection\n",
    "2. Explore Feature Table through UI\n",
    "3. Access Feature Table Information\n",
    "4. Create Feature Table from Existing UC Table\n",
    "5. Enhance Feature Table with New Features\n",
    "6. Efficient Feature Table Deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "341f47df-0215-4d89-b75d-ce6e6c0030fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "2. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "   - Click **More** in the drop-down.\n",
    "   \n",
    "   - In the **Attach to an existing compute resource** window, use the first drop-down to select your unique cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "2. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "3. Wait a few minutes for the cluster to start.\n",
    "\n",
    "4. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b53c511e-6db7-4a54-a501-ff6dfd86a126",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6954f072-5aaa-4921-abb4-8255ca7966cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Classroom Setup\n",
    "\n",
    "Before starting the demo, run the provided classroom setup script. This script will define configuration variables necessary for the demo. Execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7831fcd7-6341-4141-8f29-a3f84ad30f43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e594ded-01d8-49ce-8eb6-ab4309c34c32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Other Conventions:**\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bd81bbd-a905-4748-91e5-3915c1db2ef3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"User DB Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "343a443a-8dc5-4ade-aa9d-c57b39b33fb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53713ae9-f31a-45cc-96bb-97b690114f37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Set the path of the dataset\n",
    "shared_volume_name = 'cdc-diabetes' ## From Marketplace\n",
    "csv_name = 'diabetes_binary_5050split_BRFSS2015' ## CSV file name\n",
    "dataset_path = f\"{DA.paths.datasets.cdc_diabetes}/{shared_volume_name}/{csv_name}.csv\" ## Full path\n",
    "silver_df = spark.read.csv(dataset_path, header=\"true\", inferSchema=\"true\", multiLine=\"true\", escape='\"')\n",
    "display(silver_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65ac77a3-910b-4520-a45d-e077a401e9f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task1: Feature Selection\n",
    "\n",
    "The dataset is loaded and ready. We are assuming that most of the data cleaning and feature computation is already done and data is saved to \"silver\" table.\n",
    "\n",
    "Select these features from the dataset; **\"HighBP\", \"HighChol\", \"BMI\", \"Stroke\", \"PhysActivity\", \"GenHlth\", \"Sex\", \"Age\", \"Education\", \"Income\".**\n",
    "\n",
    "Create a `UID` column to be used as primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "638db705-2799-4b59-8060-221e0a3433d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "## select features we are interested in\n",
    "silver_df = silver_df.select(\"Diabetes_binary\", \"HighBP\", \"HighChol\", \"BMI\", \"Stroke\", \"PhysActivity\", \"GenHlth\", \"Sex\", \"Age\", \"Education\", \"Income\")\n",
    "\n",
    "## drop the target column\n",
    "silver_df = silver_df.drop(\"Diabetes_binary\")\n",
    "\n",
    "## create an id column to be used as primary key\n",
    "silver_df = silver_df.withColumn(\"UID\", monotonically_increasing_id())\n",
    "\n",
    "display(silver_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4376c76c-2e6c-40bb-a731-de79578a19b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Task 2: Create a Feature Table\n",
    "\n",
    "\n",
    "Create a feature table from the `silver_df` dataset. Define description and tags as you wish.\n",
    "\n",
    "New feature table name must be **`diabetes_features`**.\n",
    "\n",
    "**Note:** Don't define partition column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f0aa698-c5f5-4982-a50c-0aa0998f0a03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "diabetes_table_name = f\"{DA.catalog_name}.{DA.schema_name}.diabetes_features\"\n",
    "\n",
    "fe.create_table(\n",
    "    name=diabetes_table_name,\n",
    "    primary_keys=[\"UID\"],\n",
    "    df=silver_df,\n",
    "    description=\"Diabetes customer features\",\n",
    "    tags={\"source\": \"bronze\", \"format\": \"delta\", \"owner\": DA.username}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b9e5da3-4c73-4ac0-81ff-4de6328202e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Task 3: Explore Feature Table with the UI\n",
    "\n",
    "Now that the feature table is created, visit **Features** page from the left panel and review following information;\n",
    "\n",
    "* Check table columns, identify **primary key** and **partition** columns.\n",
    "\n",
    "* View **sample data**.\n",
    "\n",
    "* View table **details**. \n",
    "\n",
    "* View **history**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "176a5adf-f04f-4272-a361-5aab80d4994a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 4: Retrieve Feature Table Details\n",
    "\n",
    "Another way of accessing the feature table is using the API. Let's **list `features` and `primary_keys`** of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee70bc55-e6a1-4258-a9d0-3c5c2eda63e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ft = fe.get_table(name=diabetes_table_name)\n",
    "print(f\"Features: {ft.features}\")\n",
    "print(f\"Primary Keys: {ft.primary_keys}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "485cb8dc-a346-4cbd-89e7-b12474ca1bb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 5: Create a Feature Table from an Existing UC Table\n",
    "\n",
    "There is a table already created for you which includes diet related features. The table name is **`diet_features`**. Create a feature table for this existing table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "216715b9-ceac-4060-97ff-2f779fba9fbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"SELECT * FROM diet_features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8311da5-da6b-40bf-b684-40e5e82c238f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "ALTER TABLE diet_features ALTER COLUMN UID SET NOT NULL;\n",
    "ALTER TABLE diet_features ADD CONSTRAINT diet_features_pk_constraint PRIMARY KEY(UID);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc8bf8bd-f30b-4d9f-8bd5-69ae8fd2e4c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 6: Add New Features to Existing Table\n",
    "\n",
    "Let's collect diet features and merge them to the existing `diabetes_features` table. As both tables has `UID` as unique identifier, we will merge them based on this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdf1c6b1-65e2-490f-8ced-659563d659b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diet_features = spark.sql(\"SELECT * FROM diet_features\")\n",
    "\n",
    "fe.write_table(\n",
    "    name=diabetes_table_name,\n",
    "    df=diet_features,\n",
    "    mode=\"merge\"\n",
    ")\n",
    "\n",
    "display(fe.read_table(name=diabetes_table_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93145b1e-d1b2-47d3-8396-93645ae52bda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 7: Delete a Feature Table\n",
    "\n",
    "We merged both feature tables and we no longer need the `diet_features` table. Thus, let's delete this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2ec7719-81bd-4a0a-be63-e6cd3cf9c860",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diet_table_name = f\"{DA.catalog_name}.{DA.schema_name}.diet_features\"\n",
    "fe.drop_table(\n",
    "  name=diet_table_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0757cec8-44b7-4b39-be0f-7180869fd4cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lab, you demonstrated the use of Databricks Feature Store to perform feature engineering tasks. You executed the loading, preparation, and selection of features from a dataset, created a feature table, explored and accessed table details through both the UI and API, merged tables, and efficiently removed unnecessary ones. \n",
    "\n",
    "This hands-on experience enhanced your feature engineering skills on the Databricks platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fdca96a-63e1-4f81-808c-0e70e1ee9b2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "3.2 Lab Solution - Feature Engineering with Feature Store",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}